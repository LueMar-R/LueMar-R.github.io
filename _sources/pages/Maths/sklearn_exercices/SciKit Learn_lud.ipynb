{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn est une bibliothèque libre Python destinée à l'apprentissage automatique. Elle est développée par de nombreux contributeurs notamment, dans le monde académique, par des instituts français d'enseignement supérieur et de recherche comme l'Inria.\n",
    "\n",
    "Elle propose dans son framework de nombreuses bibliothèques d’algorithmes à implémenter clé en main, à disposition des data scientists.\n",
    "\n",
    "Elle comprend notamment des fonctions pour estimer des forêts aléatoires, des régressions logistiques, des algorithmes de classification, et les machines à vecteurs de support. Elle est conçue pour s'harmoniser avec d'autres bibliothèques libres Python, notamment NumPy et SciPy. \n",
    "\n",
    "_Source : [Wikipedia](https://fr.wikipedia.org/wiki/Scikit-learn)_\n",
    "\n",
    "\n",
    "Pour plus d'informations, consulter le [site officiel de scikit-lear](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "drinks = pd.read_csv(\"../Maths/pandas_exercices/qualite-vin-rouge.csv\")\n",
    "data = drinks.values\n",
    "X = data[:,:11]\n",
    "y = data[:,11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 11)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subdivision en échantillons d’apprentissage et de test \n",
    "\n",
    "On utilise le mudule `sklearn.modele_selection`dont la doc officielle est consultable [ici](https://scikit-learn.org/stable/modules/classes.html?highlight=model_selection#module-sklearn.model_selection)\n",
    "\n",
    "(exemple de code qui marche sur un jeu de données après son importation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1299, 11) (300, 11) (1299,) (300,)\n"
     ]
    }
   ],
   "source": [
    "#subdivision des données : exemple avec éch.test= 300 \n",
    "X_app,X_test,y_app,y_test = model_selection.train_test_split(X,y,test_size = 300, random_state = 0)\n",
    "print(X_app.shape,X_test.shape,y_app.shape,y_test.shape)\n",
    "\n",
    "# éch.app = taille de la matrice de départ (1599) - éch.test (300) = 1299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du modèle sur l’échantillon d’apprentissage (exemple de code avec la régression linéaire et polynomiale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12278587  2.22614985 -0.55153076  0.25235712  0.24746431  0.13536923\n",
      "  -0.1226654  -0.03533445  0.44953865 -0.29418977 -0.51622414]\n",
      " [-0.15609688  2.43483731  0.25597229  0.08082915  0.25254871  0.00326801\n",
      "  -0.01934333 -0.23386545  0.2316966  -0.54200419 -0.29059609]\n",
      " [ 0.03530297  1.46597539  0.25852551 -0.0603076   1.33431618 -0.02062759\n",
      "   0.02028731  1.52193285  1.44474489 -1.78597062 -0.84379093]\n",
      " [ 0.01213624 -1.17835338 -0.8896766  -0.01519475 -0.33091125  0.01924233\n",
      "  -0.01269057 -0.26549778 -0.32848966  0.8009871   0.16794296]\n",
      " [-0.03487567 -3.18477227  0.18292502  0.12127181 -1.28221676  0.01142552\n",
      "  -0.01376678 -1.44970223 -2.04506505  1.86263232  0.78058523]\n",
      " [-0.37642933 -0.50305567  0.80430051 -0.29488693 -0.21258568  0.01175952\n",
      "  -0.01698033 -0.64335219 -2.65399148  0.56065139  0.87071325]] [-0.03801806 -0.23276004  1.52212351 -0.28705098 -1.43982995 -0.64272058]\n"
     ]
    }
   ],
   "source": [
    "#création d'une instance de la classe LogisticRegression\n",
    "lr = LogisticRegression(solver=\"liblinear\")\n",
    "modele = lr.fit(X_app,y_app)\n",
    "print(modele.coef_,modele.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction sur l’échantillon test (exemple de code qui fait la prédiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modele.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  2  0  0  0]\n",
      " [ 0  0  6  3  0  0]\n",
      " [ 0  0 95 30  1  0]\n",
      " [ 0  0 40 89  4  0]\n",
      " [ 0  0  2 21  4  0]\n",
      " [ 0  0  0  1  2  0]]\n"
     ]
    }
   ],
   "source": [
    "#matrice de confusion\n",
    "#confrontation entre Y obs. sur l’éch. test et la prédiction\n",
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6266666666666667\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "acc= metrics.accuracy_score(y_test,y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3733333333333333\n"
     ]
    }
   ],
   "source": [
    "#taux d'erreur\n",
    "err= 1.0 -acc\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.75396825 0.66917293 0.14814815 0.        ]\n"
     ]
    }
   ],
   "source": [
    "#sensibilité (ou rappel)\n",
    "se = metrics.recall_score(y_test,y_pred, average = None)\n",
    "print(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation sur l’échantillon test : Erreur quadratique moyen (exemple de code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4633333333333333"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "metrics.mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisée (k-folds) (Principe + exemple de code qui permet de faire l’évaluation d’un modèle par la validation croisée\n",
    "\n",
    "La validation croisée (« cross-validation ») est, en apprentissage automatique, une méthode d’estimation de fiabilité d’un modèle fondé sur une technique d’échantillonnage. \n",
    "\n",
    "En validation croisée à _k_ blocs, _« k-fold cross-validation »_ : on divise l'échantillon original en _k_ échantillons (ou _« blocs »_ ), puis on sélectionne un des _k_ échantillons comme ensemble de validation pendant que les _k-1_ autres échantillons constituent l'ensemble d'apprentissage. Après apprentissage, on peut calculer une performance de validation. Puis on répète l'opération en sélectionnant un autre échantillon de validation parmi les blocs prédéfinis. À l'issue de la procédure nous obtenons ainsi _k_ scores de performances, un par bloc. La moyenne et l'écart type des _k_ scores de performances peuvent être calculés pour estimer le biais et la variance de la performance de validation.\n",
    "\n",
    "![kfolds.png](../../images/kfolds.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58846154, 0.55      , 0.56538462, 0.58846154, 0.57528958])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "success =  cross_val_score(modele, X_app, y_app, cv=5)\n",
    "success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch (Principe + exemple de code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   2   0   0]\n",
      " [  0   0   3   6   0   0]\n",
      " [  0   0  51  75   0   0]\n",
      " [  0   0  30 103   0   0]\n",
      " [  0   0   1  26   0   0]\n",
      " [  0   0   0   3   0   0]]\n",
      "0.5133333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "mvs= svm.SVC()\n",
    "modele2 = mvs.fit(X_app,y_app)\n",
    "\n",
    "#prédiction ech. test\n",
    "y_pred2 = modele2.predict(X_test)\n",
    "\n",
    "#matrice de confusion\n",
    "print(metrics.confusion_matrix(y_test,y_pred2))\n",
    "\n",
    "#succès en test\n",
    "print(metrics.accuracy_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinaisons de paramètres à évaluer\n",
    "parametres= [{'C':[0.1,1,10],'kernel':['rbf','linear']}]\n",
    "#évaluation en validation croisée de 3 x 2 = 6 configurations\n",
    "#accuracysera le critère à utiliser pour sélectionner la meilleure config\n",
    "#mvsest l’instance de la classe svm.SVC (cf. page précédente)\n",
    "grid= model_selection.GridSearchCV(estimator=mvs,param_grid=parametres,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           params  mean_test_score\n",
      "0     {'C': 0.1, 'kernel': 'rbf'}         0.491919\n",
      "1  {'C': 0.1, 'kernel': 'linear'}         0.567357\n",
      "2       {'C': 1, 'kernel': 'rbf'}         0.498848\n",
      "3    {'C': 1, 'kernel': 'linear'}         0.567357\n",
      "4      {'C': 10, 'kernel': 'rbf'}         0.550431\n",
      "5   {'C': 10, 'kernel': 'linear'}         0.570434\n",
      "{'C': 10, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "#lancer la recherche –attention, gourmand en calculs\n",
    "grille = grid.fit(X_app,y_app)\n",
    "#résultat pour chaque combinaison\n",
    "print(pd.DataFrame.from_dict(grille.cv_results_).loc[:,[\"params\",\"mean_test_score\"]]) \n",
    "#meilleur paramétrage\n",
    "print(grille.best_params_) # {‘C’ : 10, ‘kernel’ : ‘linear’}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meilleur performance –estimée en interne par validation croisée\n",
    "print(grille.best_score_)\n",
    "#prédiction avec le modèle «optimal» c.-à-d. {‘C’ : 10, ‘kernel’ : ‘linear’}\n",
    "y_pred3 = grille.predict(X_test)#taux de succès en testprint(metrics.accuracy_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection des variables (Principe + exemple de code avec la méthode recursive feature elimination).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleImputer\n",
    "\n",
    "Remplacer les valeurs manquantes par la moyenne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imptr = SimpleImputer( = np.nan, strategy = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition du principe de FeatureScaling + exemple de code de son utilisation avec StandardScaler\n",
    "\n",
    "Certains outils statistiques nécessitent une transformation des données afin de pouvoir être utilisés ou optimisés. Par exemple, dans le cadre de l’utilisation d’un test de Student ou bien d’une régression linéaire, l’hypothèse de normalité est primordiale.<br>\n",
    "Ou encore, dans le cas où les données ne répondent pas aux hypothèses recquises, les équivalents non paramétriques de la théorie des tests nécessitent une transformation des données en vecteur des rangs associés aux données.<br>\n",
    "\n",
    "Les méthodes de transformation des données se déclinent donc en trois familles:<br>\n",
    "* la standardisation ou l’action de centrer-réduire les données pour diminuer l’échelle de dispersion tout en conservant la forme des distributions conjointes (moyenne = 0 et ecart-type = 1)  (= centrer-réduire la matrice X en retranchant pour chaque vecteur Xj sa moyenne et en divisant par son écart-type)\n",
    "\n",
    "* la transformation en vecteur de rangs dont l’objectif est de se concentrer sur l’ordre des valeurs des données et plus sur les valeurs elles-mêmes,\n",
    "\n",
    "* la normalisation des données. Normaliser les données revient à appliquer une fonction f sur Xj tel que f(j) suit une loi normale. Plusieurs méthodes simples existent : l'élévation au carré, la transformation logarithmique, la transformation arc-sinus, exponentielle, racine carrée, etc. Cependant, ces méthodes requièrent l’absence de valeurs négatives (à l’exception de la mise à l’exponentielle et de la transformation inverse). Il existe d'autres outils de normalisation plus performants comme la normalisation de box-cox\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
